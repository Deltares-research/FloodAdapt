{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3eeb3b9",
   "metadata": {},
   "source": [
    "# 📘 Example: Simple Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b578e99e",
   "metadata": {},
   "source": [
    "In this notebook we demonstrate the **workflow** on how you can build a simple **FloodAdapt scenario** in Charleston, USA, using the **API**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ea5e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "In this notebook we will cover the following steps:\n",
    "\n",
    "1. Create a synthetic **event** \n",
    "2. Create a **projection** - Sea level rise (SLR)\n",
    "3. Create a **measure** and **strategy** - Seawall\n",
    "4. Create and run a **scenario**\n",
    "6. Investigate the **output**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f84cb9c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc26c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import contextily as cx\n",
    "from datetime import datetime\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "\n",
    "import flood_adapt.objects.forcing as f\n",
    "import flood_adapt.objects.measures as m\n",
    "from flood_adapt.objects import TimeFrame\n",
    "from flood_adapt.config.sfincs import RiverModel\n",
    "from flood_adapt.dbs_classes.database import Database\n",
    "from flood_adapt.objects.events.synthetic import SyntheticEvent \n",
    "from flood_adapt.flood_adapt import FloodAdapt\n",
    "\n",
    "from flood_adapt.objects.projections.projections import Projection, PhysicalProjection, SocioEconomicChange\n",
    "from flood_adapt.objects.scenarios.scenarios import Scenario\n",
    "from flood_adapt import Settings\n",
    "from flood_adapt.objects.strategies.strategies import Strategy\n",
    "from flood_adapt import unit_system as us"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18aaad0",
   "metadata": {},
   "source": [
    "## 🚀 **Step 1**. Reading-in the FloodAdapt database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0fbef4",
   "metadata": {},
   "source": [
    "Let's start with initiating the database and FloodAdapt class. \n",
    "1. Initiate the database class [`Settings`](../../api_ref/Settings.qmd) by defining the `DATABASE_ROOT` and `DATABASE_NAME`.\n",
    "2. Initiate the [`FloodAdapt`](../../api_ref/FloodAdapt.qmd) class by parsing the `Settings().database_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "385634d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Settings\n  Value error, Database root C:\\Users\\rautenba\\repos\\FloodAdapt\\docs\\examples\\_data\\examples does not exist. [type=value_error, input_value={'DATABASE_ROOT': Windows...AME': 'charleston_test'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m STATIC_DATA_DIR = Path(\u001b[33m\"\u001b[39m\u001b[33m../_data/examples/static-data/3_Measures\u001b[39m\u001b[33m\"\u001b[39m).resolve()\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Set up the settings for the database\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mSettings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mDATABASE_ROOT\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../_data/examples\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mDATABASE_NAME\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcharleston_test\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Create the FloodAdapt instance\u001b[39;00m\n\u001b[32m     11\u001b[39m fa = FloodAdapt(Settings().database_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rautenba\\repos\\FloodAdapt\\.pixi\\envs\\docs\\Lib\\site-packages\\pydantic_settings\\main.py:176\u001b[39m, in \u001b[36mBaseSettings.__init__\u001b[39m\u001b[34m(__pydantic_self__, _case_sensitive, _nested_model_default_partial_update, _env_prefix, _env_file, _env_file_encoding, _env_ignore_empty, _env_nested_delimiter, _env_nested_max_split, _env_parse_none_str, _env_parse_enums, _cli_prog_name, _cli_parse_args, _cli_settings_source, _cli_parse_none_str, _cli_hide_none_type, _cli_avoid_json, _cli_enforce_required, _cli_use_class_docs_for_groups, _cli_exit_on_error, _cli_prefix, _cli_flag_prefix_char, _cli_implicit_flags, _cli_ignore_unknown_args, _cli_kebab_case, _secrets_dir, **values)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    148\u001b[39m     __pydantic_self__,\n\u001b[32m    149\u001b[39m     _case_sensitive: \u001b[38;5;28mbool\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    174\u001b[39m     **values: Any,\n\u001b[32m    175\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_settings_build_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_case_sensitive\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_case_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_nested_model_default_partial_update\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_nested_model_default_partial_update\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_env_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_env_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_env_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_env_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_env_file_encoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_env_file_encoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_env_ignore_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_env_ignore_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_env_nested_delimiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_env_nested_delimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_env_nested_max_split\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_env_nested_max_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_env_parse_none_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_env_parse_none_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_env_parse_enums\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_env_parse_enums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_prog_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_prog_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_parse_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_parse_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_settings_source\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_settings_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_parse_none_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_parse_none_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_hide_none_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_hide_none_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_avoid_json\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_avoid_json\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_enforce_required\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_enforce_required\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_use_class_docs_for_groups\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_use_class_docs_for_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_exit_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_exit_on_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_flag_prefix_char\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_flag_prefix_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_implicit_flags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_implicit_flags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_ignore_unknown_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_ignore_unknown_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_cli_kebab_case\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_cli_kebab_case\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_secrets_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_secrets_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rautenba\\repos\\FloodAdapt\\.pixi\\envs\\docs\\Lib\\site-packages\\pydantic\\main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for Settings\n  Value error, Database root C:\\Users\\rautenba\\repos\\FloodAdapt\\docs\\examples\\_data\\examples does not exist. [type=value_error, input_value={'DATABASE_ROOT': Windows...AME': 'charleston_test'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error"
     ]
    }
   ],
   "source": [
    "# Define the static data folder\n",
    "STATIC_DATA_DIR = Path(\"../_data/examples/static-data/3_Measures\").resolve()\n",
    "\n",
    "# Set up the settings for the database\n",
    "Settings(\n",
    "    DATABASE_ROOT=Path(\"../_data/examples\").resolve(),\n",
    "    DATABASE_NAME=\"charleston_test\"\n",
    ")\n",
    "\n",
    "# Create the FloodAdapt instance\n",
    "fa = FloodAdapt(Settings().database_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6d41b3",
   "metadata": {},
   "source": [
    "## 🌊 **Step 2**. Events - Create a synthetic Event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff7ec2",
   "metadata": {},
   "source": [
    "Events in FloodAdapt are categorized into different forcings:\n",
    "1. **Wind**\n",
    "2. **Rainfall**\n",
    "3. **Discharge**\n",
    "4. **Water Level**\n",
    "\n",
    "If you want to learn more about the individual forcings in FloodAdapt, please go and read the section on [**Events**](../../4_user_guide/events/index.qmd) in the FloodAdapt documentation.\n",
    "\n",
    "When creating an event, we need to create an [`Event`](../../api_ref/Event.qmd) object. Depending on which type of event we create, we select a different class. In this example we create a **synthetic event**, therefore we use the [`SyntheticEvent`](../../api_ref/objects/SyntheticEvent.qmd) class. \n",
    "\n",
    "To create the `SyntheticEvent` object we use the `time` attribute to define the event duration. This should be parsed as a [`TimeFrame`](../../api_ref/TimeFrame.qmd) object. In the [`forcings`](../../api_ref/IForcing.qmd) attribute we aggregated the different forcing objects in a dictionary.  \n",
    "\n",
    "In this event example we will create an event with the following `forcings`:  \n",
    "🌬️ `WindConstant`: Define a value for a constant wind speed (mps) and direction (degrees)  \n",
    "🌧️ `RainfallConstant`: Define a value for a constant rainfall (mm/hr)  \n",
    "💦 `DischargeConstant`: Define the x and y coordinates of the discharge point of the Cooper River and a value for a constant mean discharge (cfs) in the River- and Discharge model (same value)  \n",
    "🌊 `WaterlevelSynthetic SurgeModel`: Define a peak time (h), peak value in (m) and duration (d)  \n",
    "↔️ `WaterlevelSynthetic TideModel`: Define the harmonic amplitude (m), harmonic period (h) and harmonic phase (h)  \n",
    "\n",
    "For a complete guide on all the possible event options and inputs check out the [**notebook**](../events/index.qmd) specifically on **events**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ff3fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic event object\n",
    "attrs_event = SyntheticEvent(\n",
    "        name=\"synthetic_nearshore\",\n",
    "        description = \"This is a synthetic nearshore event\",\n",
    "        time=TimeFrame(\n",
    "            start_time=datetime(2020, 1, 1),\n",
    "            end_time=datetime(2020, 1, 2),\n",
    "        ),\n",
    "        forcings={\n",
    "            f.forcing.ForcingType.WIND: [\n",
    "                f.wind.WindConstant(\n",
    "                    speed=us.UnitfulVelocity(value=5, units=us.UnitTypesVelocity.mps),\n",
    "                    direction=us.UnitfulDirection(\n",
    "                        value=60, units=us.UnitTypesDirection.degrees\n",
    "                    ),\n",
    "                )\n",
    "            ],\n",
    "            f.forcing.ForcingType.RAINFALL: [\n",
    "                f.rainfall.RainfallConstant(\n",
    "                    intensity=us.UnitfulIntensity(\n",
    "                        value=20, units=us.UnitTypesIntensity.mm_hr\n",
    "                    )\n",
    "                )\n",
    "            ],\n",
    "            f.forcing.ForcingType.DISCHARGE: [\n",
    "                f.discharge.DischargeConstant(\n",
    "                    river=RiverModel(\n",
    "                        name=\"cooper\",\n",
    "                        description=\"Cooper River\",\n",
    "                        x_coordinate=595546.3,\n",
    "                        y_coordinate=3675590.6,\n",
    "                        mean_discharge=us.UnitfulDischarge(\n",
    "                            value=5000, units=us.UnitTypesDischarge.cfs\n",
    "                        ),\n",
    "                    ),\n",
    "                    discharge=us.UnitfulDischarge(\n",
    "                        value=5000, units=us.UnitTypesDischarge.cfs\n",
    "                    ),\n",
    "                )\n",
    "            ],\n",
    "            f.forcing.ForcingType.WATERLEVEL: [\n",
    "                f.waterlevels.WaterlevelSynthetic(\n",
    "                    surge=f.waterlevels.SurgeModel(\n",
    "                        timeseries=f.timeseries.TimeseriesFactory.from_args(\n",
    "                            shape_type=f.timeseries.ShapeType.triangle,\n",
    "                            duration=us.UnitfulTime(\n",
    "                                value=1, units=us.UnitTypesTime.days\n",
    "                            ),\n",
    "                            peak_time=us.UnitfulTime(\n",
    "                                value=8, units=us.UnitTypesTime.hours\n",
    "                            ),\n",
    "                            peak_value=us.UnitfulLength(\n",
    "                                value=1, units=us.UnitTypesLength.meters\n",
    "                            ),\n",
    "                        )\n",
    "                    ),\n",
    "                    tide=f.waterlevels.TideModel(\n",
    "                        harmonic_amplitude=us.UnitfulLength(\n",
    "                            value=1, units=us.UnitTypesLength.meters\n",
    "                        ),\n",
    "                        harmonic_period=us.UnitfulTime(\n",
    "                            value=12.4, units=us.UnitTypesTime.hours\n",
    "                        ),\n",
    "                        harmonic_phase=us.UnitfulTime(\n",
    "                            value=0, units=us.UnitTypesTime.hours\n",
    "                        ),\n",
    "                    ),\n",
    "                )\n",
    "            ],\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efafa7ba",
   "metadata": {},
   "source": [
    "### 💾 **Step 2.1**. Saving the event to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3cf036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the event to the database\n",
    "fa.save_event(attrs_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d957ab90",
   "metadata": {},
   "source": [
    "## 📈 **Step 3**. Projections - Create a projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b05001f",
   "metadata": {},
   "source": [
    "**Projections** in FloodAdapt allow us to adjust our model to future conditions such as sea level rise or/and population growth. If you want to learn more about projections in FlooAdapt, please go to the section [Projections](../../4_user_guide/projections/index.qmd) in the FloodAdapt documentation. \n",
    "  \n",
    "The projections can be divided into two categories:\n",
    "1. 🌊 **Physical Projections**: Sea level rise, intensified precipitation, increased storm frequency\n",
    "2. 💰 **Socio economic change**: Population growth (existing built area, new development area), economic growth\n",
    "\n",
    "When creating a projection we need to create a [`Projection`](../../api_ref/Projection.qmd) object. The `PhysicalProjection` attribute is parsed as a [`PhysicalProjection`](../../api_ref/PhysicalProjection.qmd) object which captures the pysical projection such as sea lvel rise. The `SocioEconomicChange` attribute is parsed as a [`SocioEconomicChange`](../../api_ref/SocioEconomicChange.qmd) object which captures the socioeconomic projection such as population growth. It's not mandatory to parse both projections. If we only want to use one of the two types of projections we can leave the other one blank (). \n",
    "\n",
    "The attributes of the `PhysicalProjection` or `SocioEconomicChange` object define the projection. In this case we parse the attribute `sea_level_rise` to the `PhysicalProjection` object and define the value in [`UnitfulLength`](../../api_ref/UnitfulLength.qmd) and the unit in [`UnitTypesLength`](../../api_ref/UnitTypesLength.qmd).\n",
    "\n",
    "To get a deeper understanding for all the possible projections and their inputs go to the [**notebook**](../projections/index.qmd) specifically about **projections**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69258cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a projection object\n",
    "attrs_projection = Projection(\n",
    "    name=\"SLR_2ft\",\n",
    "    description = \"This is a 2ft SLR projection\",\n",
    "    physical_projection=PhysicalProjection(\n",
    "        sea_level_rise=us.UnitfulLength(value=2, units=us.UnitTypesLength.feet),\n",
    "    ),\n",
    "    socio_economic_change=SocioEconomicChange(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d52add",
   "metadata": {},
   "source": [
    "### 💾 **Step 3.1**. Saving the projection to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ebc6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the projection\n",
    "fa.save_projection(attrs_projection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27ba1f7",
   "metadata": {},
   "source": [
    "## 🧱 **Step 4**. Measures - Create a measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8aa165",
   "metadata": {},
   "source": [
    "**Measures** in FloodAdapt enable the user to mititgate the event impacts and investigate their efficiency on the fly.\n",
    "\n",
    "Measures can be:\n",
    "1. 💦 **Hydraulic** measures on the hazard level\n",
    "2. 🌱 **Green infrastructure** measures on the hazard level\n",
    "3. 🏠 **Impact** measures on the building level.\n",
    "\n",
    "You can read more about measures in the section [Measures](../../4_user_guide/measures/index.qmd) in the FloodAdapt documentation. \n",
    "\n",
    "💦 In this example we will create a **hydraulic measure**, a sea wall of 12ft. To create a measure we need to create a [`Measure`](../../api_ref/Measure.qmd) object. \n",
    "In the attributes we define the measure `type` object, in this example a [`FloodWall`](../../api_ref/objectS/FloodWall.qmd) object. Additionally to the other attributes, we need to parse the `elevation` value as [`UnitfulLength`](../../api_ref/UnitfulLength.qmd) and the unit as [`UnitTypesLength`](../../api_ref/UnitTypesLength.qmd) of the sea wall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a measure object\n",
    "attrs_measure_phy = m.measures.FloodWall(\n",
    "        name= \"Seawall_12ft\",\n",
    "        description = \"12ft Seawall\",\n",
    "        type = m.measures.MeasureType.floodwall,\n",
    "        selection_type = m.measures.SelectionType.polyline,\n",
    "        polygon_file = str(Path(STATIC_DATA_DIR / \"seawall.geojson\")),\n",
    "        elevation = us.UnitfulLength(value=12, units=us.UnitTypesLength.feet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c108a00",
   "metadata": {},
   "source": [
    "🏠 Let's add another measure on the **impact level**. We can elevate buildings in a specific area to mititgate the impact on these assets.\n",
    "\n",
    "When elevating buildings as measure we need to create a [`Elevate`](../../api_ref/objectS/Elevate.qmd) object. we can also specify which building types we wan the measure to be applied to by defining the `property type` attribute. e can parse the building type (residential, commercial...) that is used in our Delft-FIAT Model. In this example we want to elevate all buildings so we parse `ALL`.  \n",
    "\n",
    "To define the `elevation` we need to parse a [`UnitfulLengthRefValue`]() object which consists of a `value` of type float, a `unit` which can be one of the [`UnitTypesLength`](../../api_ref/UnitTypesLength.qmd) and a vertical reference from which point the elevation should be calculated. This sholud be parsed as [`VerticalReference`]() object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f905d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a measure object\n",
    "attrs_measure_elev = m.measures.Elevate(\n",
    "        name= \"Elevated_homes\",\n",
    "        description = \"Elevate residential buildings\",\n",
    "        type = m.measures.MeasureType.elevate_properties,\n",
    "        selection_type = m.measures.SelectionType.polygon,\n",
    "        polygon_file = str(Path(STATIC_DATA_DIR / \"raise_property_polygon.geojson\")),\n",
    "        property_type = \"ALL\",\n",
    "        elevation = us.UnitfulLengthRefValue(value=1, units=us.UnitTypesLength.feet, type = us.VerticalReference.floodmap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e0cfd5",
   "metadata": {},
   "source": [
    "### 💾 **Step 4.1**. Saving the measure to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23bc0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the measure\n",
    "fa.save_measure(attrs_measure_phy)\n",
    "fa.save_measure(attrs_measure_elev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3065e2",
   "metadata": {},
   "source": [
    "## 🧩 **Step 5**. Strategies - Create a strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070e7fc4",
   "metadata": {},
   "source": [
    "**Strategies** are combinations **measures**. They allow us to run an test multiple measures in a single model run. \n",
    "\n",
    "To create a strategy we need to create a [`Strategy`](../../api_ref/Strategy.qmd) object. In the `measures` attribute we parse a list of all the names of the measures that we want to apply in that strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5610082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a strategy object\n",
    "attrs_strategy = Strategy(\n",
    "        name= \"seawall_and_elev_build\",\n",
    "        description = \"Strategy with a seawall and elevation of buildings\",\n",
    "        measures = [attrs_measure_phy.name, attrs_measure_elev.name],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0252b6",
   "metadata": {},
   "source": [
    "### 💾 **Step 5.1**. Saving the strategy to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca770396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the stategy\n",
    "fa.save_strategy(attrs_strategy )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d60e313",
   "metadata": {},
   "source": [
    "## 🗺️ **Step 6**. Create a scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeb7271",
   "metadata": {},
   "source": [
    "We reached the final step where we can put all the building blocks together to create a complete scenario!  \n",
    "A scenario is composed of:\n",
    "\n",
    "**1. Event**  \n",
    "**2. Projection**  \n",
    "**3. Strategy (Measures)**\n",
    "\n",
    "If you want to read more about the composition of scenarios, go read the [**Scenario**](https://deltares-research.github.io/FloodAdapt/4_user_guide/scenarios/)-section of the FloodAdapt documentation. \n",
    "\n",
    "When creating a scenario we need to create a [`Scenario`](../../api_ref/Scenario.qmd) object in which we parse the name of the `event`, `projection` and `strategy` as attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95185c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scenario object\n",
    "scenario = Scenario(\n",
    "    name = \"slr_nearshore_seawall_elev_build\",\n",
    "    description = \"Nearshore event with SLR projection and seawall + elevated buildings strategy\",\n",
    "    event =  attrs_event.name,\n",
    "    projection =  attrs_projection.name,\n",
    "    strategy = attrs_strategy.name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a04f1",
   "metadata": {},
   "source": [
    "### 💾 **Step 6.1**. Saving the strategy to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bd548b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, '')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the scenario\n",
    "fa.save_scenario(scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42855768",
   "metadata": {},
   "source": [
    "## 🏃‍♀️ **Final step**: Run a scenario\n",
    "\n",
    "We are ready to **run** the scenario! Simply parse the `scenario.name` into the function `run_scenario`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb161703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 12:03:01 PM - FloodAdapt.SfincsAdapter - WARNING - Failed to add event rainfall multiplier, no rainfall forcing found in the model.\n",
      "2025-05-15 12:03:01 PM - FloodAdapt.SfincsAdapter - WARNING - Could not use height data from file due to missing `z` column or missing values therein. Using uniform height of 12.0 feet instead.\n"
     ]
    }
   ],
   "source": [
    "# Run the scenario\n",
    "fa.run_scenario(scenario.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e07e77",
   "metadata": {},
   "source": [
    "## **Finished!** \n",
    "**Congratulations** you created and ran your first FloodAdapt scenario!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68089740",
   "metadata": {},
   "source": [
    "## **Output**: 🕵️‍♀️ Let's inspect the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4797ef",
   "metadata": {},
   "source": [
    "#### **1. Output files**\n",
    "In your scenario output folder you should see the following files:\n",
    "- **Flooding**: Folder\n",
    "- **Impacts**: Folder\n",
    "- **finished.txt**: text file\n",
    "- **Infometrics_\"*scenario_name*\".csv**: csv file of the overall infometrics\n",
    "- **Infometrics_\"*scenario_name*\"_\"*aggregation_layer*\".csv**: csv file  of the aggregated areas. You have one file per aggregation level. In this example we have two files. \n",
    "- **logfile_\"*scenario_name*\".log**: The log of the scenario run\n",
    "- **\"*scenario_name*\"_metrics.html**: A metric file of your scenario output\n",
    "\n",
    "The figure below presents a visual overview of all the output files that should be in your database after running the scenario\n",
    "<div>\n",
    "<img src=\"../_static/images/output_folder_event.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5c8fb6",
   "metadata": {},
   "source": [
    "#### **2. Floodmap** - Inspect the floodmap\n",
    "\n",
    "We can open and inspect the floodmap geotiff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80f229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"../_data/examples/charleston_test\").resolve()\n",
    "\n",
    "# Open floodmap geotiff\n",
    "data_name = root / \"output\"/ \"scenarios\" / \"slr_nearshore_seawall_elev_build\" / \"Flooding\" / \"FloodMap_slr_nearshore_seawall_elev_build.tif\"\n",
    "tiff = rasterio.open(data_name)\n",
    "\n",
    "# Plot floodmap\n",
    "rasterio.plot.show(tiff, title = \"Floodmap nearshore scenario with 2ft SLR, seawall & elevated buildings\", cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2af65c5",
   "metadata": {},
   "source": [
    "#### **3. Economic Impacts** - Inspect the economic impacts on the building level and aggregated\n",
    "\n",
    "We can plot the economic impacts on the building level and on the aggregated level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee59e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building Impacts\n",
    "# Open building impacts\n",
    "gdf_impacts_buildings = gpd.read_file(root / \"output\" / \"scenarios\" / \"slr_nearshore_seawall_elev_build\" / \"Impacts\" / \"Impacts_building_footprints_slr_nearshore_seawall_elev_build.gpkg\")\n",
    "\n",
    "# Reproject buildings crs to Web Mercator\n",
    "gdf_impacts_buildings =gdf_impacts_buildings.to_crs(epsg=3857)\n",
    "\n",
    "# Plot building impacts\n",
    "ax = gdf_impacts_buildings.plot(figsize=(10, 10),column = \"Total Damage\",cmap=\"Reds\", legend = True, vmin= 0, vmax= 60000, legend_kwds={\"label\": \"Total Damages ($) Buildings\",\"orientation\": \"horizontal\"})\n",
    "cx.add_basemap(ax)\n",
    "ax.plot()\n",
    "\n",
    "## Aggregated Impacts\n",
    "# Open aggregated impacts\n",
    "gdf_impacts_aggr = gpd.read_file(root / \"output\" / \"scenarios\" / \"slr_nearshore_seawall_elev_build\" / \"Impacts\" / \"Impacts_aggregated_slr_nearshore_seawall_elev_build_aggr_lvl_2.gpkg\")\n",
    "\n",
    "# Reproject buildings crs to Web Mercator\n",
    "gdf_impacts_aggr = gdf_impacts_aggr.to_crs(epsg=3857)\n",
    "# Plot aggregated impacts\n",
    "ax = gdf_impacts_aggr.plot(figsize=(10, 10),column = \"TotalDamageEvent\",cmap=\"Reds\", legend = True, vmin= 0, vmax= 10000000, edgecolor=\"k\", legend_kwds={\"label\": \"Total Damages ($) per aggregatetion area\", \"orientation\": \"horizontal\"})\n",
    "cx.add_basemap(ax)\n",
    "ax.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97486347",
   "metadata": {},
   "source": [
    "#### **4. Infometrics & Infographics**\n",
    "Which **infometrics** and **infographics** to generate can be defined in the infometrics andd infographics and configuration file in your database */Database/charleston_full/static/templates/infometrics/\"\"*, */Database/charleston_full/static/templates/infographics/\"\".toml*, respectively.\n",
    "\n",
    "The figure below shows the infographics of the scenario we created above. \n",
    "<div>\n",
    "<img src=\"example_chaleston3.png\" width=\"600\"/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
