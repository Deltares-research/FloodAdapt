{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# üìò Example: Database Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrate how to use the **Database builder** of FloodAdapt, which greatly simplifies the process of setting up a FloodAdapt database in a new location!\n",
    "\n",
    "The most critical components of a FloodAdapt database are the [**SFINCS**](https://github.com/Deltares/SFINCS) and [**Delft-FIAT**](https://github.com/Deltares/Delft-FIAT) models, both of which can be generated with great ease using the [**HydroMT-SFINCS**](https://deltares.github.io/hydromt_sfincs/latest/) and the [**HydroMT-FIAT**](https://deltares.github.io/hydromt_fiat/stable/) plugins of [**HydroMT**](https://deltares.github.io/hydromt/latest/).\n",
    "\n",
    "For this notebook, we will use an example area in Charleston, USA, for which we have already generated a SFINCS and a Delft-FIAT model.\n",
    "\n",
    "In order to use the **DatabaseBuilder** of FloodAdapt a set of **configuration** parameters are needed. The **configuration** parameters can be divided to **mandatory** and **optional** ones. Using only the mandatory parameters (i.e., baseline FloodAdapt configuration) will result in a simple but functional version of FloodAdapt. By adding optional parameters to your configuration, you can create a more advanced FloodAdapt database with additional features. \n",
    "\n",
    "If you want to learn more about the configuration parameters, please refer to the [Database-Builder](../../3_setup_guide/database.qmd) of the Setup Guide in the documentation.\n",
    "\n",
    "The configuration can be either created through available FloodAdapt classes or can be parsed as a simple dictionary. We advice you to work with the FloodAdapt classes, since this can avoid using wrong parameter names or values with the help of type hinting. \n",
    "\n",
    "In this notebook we will start by creating a simple FloodAdapt database using the baseline FloodAdapt configuration ([Step-2: Build a basic FloodAdapt database](#-step-2-build-a-basic-floodadapt-database)), and then we will go through all the optional configuration parameters and create a more complex database ([Step-4: Build an advanced FloodAdapt Database](#Ô∏è-step-4-build-an-advanced-floodadapt-model))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import toml\n",
    "from pathlib import Path\n",
    "from shapely.geometry import Polygon\n",
    "from hydromt_fiat.fiat import FiatModel\n",
    "from hydromt_sfincs.sfincs import SfincsModel\n",
    "import flood_adapt.adapter.fiat_adapter as fiat\n",
    "import flood_adapt.database_builder.database_builder as db\n",
    "from flood_adapt import FloodAdapt\n",
    "from flood_adapt.objects.forcing.tide_gauge import TideGaugeSource\n",
    "from flood_adapt.objects.forcing.timeseries import Scstype\n",
    "from flood_adapt.config.config import Settings\n",
    "from flood_adapt import unit_system as us\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## üîç **Step 1**. Explore the SFINCS and Delft-FIAT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "The study area is in **Charleston, USA**, a coastal city on the East Coast of the United States. \n",
    "\n",
    "We can first inspect the extents of our SFINCS model, by loading the model with the HydroMT-SFINCS plugin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the static data folder\n",
    "STATIC_DATA_DIR = Path(\"../../../_data/examples/static-data/1_DatabaseBuilder\").resolve()\n",
    "\n",
    "fn_sfincs = STATIC_DATA_DIR  / \"overland\"\n",
    "\n",
    "sfincs = SfincsModel(root=str(fn_sfincs), mode=\"r\")\n",
    "sfincs.read()\n",
    "gdf = sfincs.region[[\"geometry\"]]\n",
    "gdf[\"name\"] = \"SFINCS Model Extent\"\n",
    "gdf.explore(\n",
    "    style_kwds={\"fillColor\": \"blue\", \"color\": \"black\", \"weight\": 1, \"fillOpacity\": 0.2},\n",
    "    tiles=\"CartoDB positron\",\n",
    "    column=\"name\",\n",
    "    legend=True,\n",
    "    legend_kwds={\"caption\": \"Region\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Then we can inspect the exposure objects (buildings and roads) of the Delft-FIAT model, by loading the model with the HydroMT-FIAT plugin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_fiat = STATIC_DATA_DIR  / \"fiat\"\n",
    "\n",
    "fiat = FiatModel(root=str(fn_fiat), mode=\"r\")\n",
    "fiat.read()\n",
    "\n",
    "# Get the geodataframe with exposure data\n",
    "gdf = fiat.exposure.get_full_gdf(fiat.exposure.exposure_db)\n",
    "\n",
    "# Plot the region and the secondary_object_types of the exposure data\n",
    "gdf.explore(column=\"secondary_object_type\", \n",
    "                name=\"Exposure types\",\n",
    "                tiles=\"CartoDB positron\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## üìÑ **Step 2**: Build a **basic** FloodAdapt Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "In this step we will create a basic FloodAdapt database, using only the mandatory configuration parameters.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### üìö **Step 2a**: Build the configuration from the **Database Builder classes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "To create the configuration object we can use the `ConfigModel` class of the Database Builder.\n",
    "\n",
    "The mandatory configuration attributes include the `name` of the database and the `database_path` which points to the location where the database will be stored. Then, a `unit_system` needs to be specified, which can be either `metric` or `imperial`. The `unit_system` will determine the default units used in the database. For the output visualizations, scaling values need to be specified for each output type, using the `gui` attribute. \n",
    "\n",
    "Last, the overland SFINCS model and the Delft-FIAT model need to be specified. The SFINCS model is specified using the `sfincs_overland` attribute, which includes the path to the SFINCS model and the vertical reference that the model has. The Delft-FIAT model is specified using the `fiat` attribute, which points to the path of the Delft-FIAT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO change gui attribute to visualization\n",
    "# TODO change FloodModel name to path\n",
    "\n",
    "# Initiate the config_model for a simple FloodAdapt Database configuration file \n",
    "config_model = db.ConfigModel(\n",
    "    name=\"charleston_example_basic\",\n",
    "    database_path= str((STATIC_DATA_DIR /\"Database\").absolute().as_posix()),\n",
    "    unit_system= db.UnitSystems.imperial,\n",
    "    gui=db.GuiConfigModel(\n",
    "        max_flood_depth=5,\n",
    "        max_aggr_dmg=1e6,\n",
    "        max_footprint_dmg=250000,\n",
    "        max_benefits=5e6,\n",
    "    ),\n",
    "    sfincs_overland=db.FloodModel(\n",
    "        name=str((STATIC_DATA_DIR  / \"overland\").absolute().as_posix()),\n",
    "        reference=\"MSL\",\n",
    "    ),\n",
    "    fiat=str((STATIC_DATA_DIR / \"fiat\").absolute().as_posix()),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### üìñ **Step 2b**: Create a configuration file from a **dictionary**\n",
    "\n",
    "An alternative approach, would be to create a dictionary with all the attributes and save it to a TOML file. Any path that is included in the file should be either an absolute path (using forward slashes `/`) or a relative path (using forward slashes `/` and relative to the path of the TOML file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case we use relative paths, but absolute paths are also possible\n",
    "config_dict = {\n",
    "\"name\": \"charleston_example_basic\",\n",
    "\"database_path\": \"Database\",\n",
    "\"sfincs_overland\" : { \n",
    "    \"name\":\"overland\",\n",
    "    \"reference\":\"MSL\"\n",
    "    },\n",
    "\"fiat\" : \"fiat\",\n",
    "\"unit_system\" :\"imperial\",\n",
    "\"gui\": {\n",
    "\"max_flood_depth\": 5,\n",
    "\"max_aggr_dmg\" : 1e6,\n",
    "\"max_footprint_dmg\": 250000,\n",
    "\"max_benefits\" : 5e6}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "We can then save the configuration as a .toml file at the location of the other input data, that we defined in the dictionary as relative paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the configuration file\n",
    "config_path = STATIC_DATA_DIR  / \"db_config_basic.toml\"\n",
    "with open(config_path, \"w\") as f:\n",
    "    toml.dump(config_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "The we can use the `read()` method of the `ConfigModel` class to read the configuration from the TOML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = db.ConfigModel.read(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "We can then verify that the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "config == config_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## üèÉ‚Äç‚ôÄÔ∏è **Step 3**: Run the Database Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "We are ready to run the Database Builder with the configuration that we just created above. First we are going to run **Option 2a** - in which we generated the configuration using the FloodAdapt classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Option 2a -  DB-builder config from FloodAdapt classes\n",
    "db_build = db.DatabaseBuilder(config_model)\n",
    "db_build.build(overwrite= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Now you created two complete FloodAdapt Database. Both databases should be identical as we used the same inputs. You can open the databases in the GUI and explore them further or continue working with the database through the API. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è **Step 4**. Build an **advanced** FloodAdapt model\n",
    "\n",
    "In the previous step we created a simple FloodAdapt model. Our simple database is limited in functionality, so in this next step we're adding more advanced configurations to expand its capabilities so that we can create a comprehensive FloodAdapt model. \n",
    "\n",
    "The configuration file consists of:\n",
    "1. **Basic model parameters** to create a simple FloodAdapt database.\n",
    "2. **Advance model parameters** to create a more complex FloodAdapt database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### üìö **Step 2a**: Build the configuration from the **Database Builder classes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "First, we need to define the basic parameters like the `name` and `database_path`, together with the `unit_system` as an `UnitSystem` object and the `gui` variables, which we aggregate in the `GuiConfigModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the basic parameters\n",
    "name=\"charleston_example_advanced1\"\n",
    "database_path= str((STATIC_DATA_DIR / \"Database\").absolute())\n",
    "unit_system= db.UnitSystems.imperial\n",
    "gui=db.GuiConfigModel(\n",
    "    max_flood_depth=5,\n",
    "    max_aggr_dmg=1e6,\n",
    "    max_footprint_dmg=250000,\n",
    "    max_benefits=5e6,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Additionally, to the basic model parameters we can add more parameters to make the database more complex. \n",
    "\n",
    "**Risk**   \n",
    "We can add a probabilistic event set by providing the filepath the risk event in the attribute `probabilistic_set`. If we add risk to our database we can set the `infographics` to `True`.\n",
    "We also need to define the `return_periods` in form of a list of integers or floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add risk parameters\n",
    "probabilistic_set=str(Path(STATIC_DATA_DIR  / \"test_set\"))\n",
    "infographics=True\n",
    "return_periods=[1, 2, 5, 10, 25, 50, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "We need to define the **sfincs model(s)** for our database. We need to add the `sfincs_overland` model by passing a dictionary with the entries: `name`, the file path,  and `reference`, the reference system (eg. \"MSL\").\n",
    " \n",
    "If we have a SFINCS offshore model we can also pass this into the configuration to the `sfincs_offshore` attribute in he same way as the overland model. For the offshore model we need to add an extra entry to the dictionary. We need to add the value and unit of the `vertical_offset`, which describes the offshore water level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the sfincs model(s)\n",
    "sfincs_overland=db.FloodModel(\n",
    "    name=str((STATIC_DATA_DIR  / \"overland\").absolute()),\n",
    "    reference=\"MSL\",\n",
    ")\n",
    "sfincs_offshore=db.FloodModel(\n",
    "    name=str(Path(STATIC_DATA_DIR / \"offshore\")),  #TODO fix final path\n",
    "    reference=\"MSL\",\n",
    "    vertical_offset=us.UnitfulLength(\n",
    "        value=0.33, units=us.UnitTypesLength.feet\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Next we must pass a **DEM** in form of a dictionary with the entries: `filename` and `units`. The `units` should be passed as [`UnitTypesLength`](../../api_ref/UnitTypesLength.qmd) object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the DEM\n",
    "dem=db.DemModel(\n",
    "    filename=str(Path(STATIC_DATA_DIR / \"charleston_14m.tif\")), \n",
    "    units=us.UnitTypesLength.meters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "We can also exclude specific datums which we can define in the `excluded_datums` attribute. We can pass a list of datums. <span style=\"color:red;\">Why exclude datums? What does that mean in this context</span>\n",
    "\n",
    "**Important!**  <span style=\"color:red;\">double check</span>\n",
    "The water level reference should be set to the reference of your DEM. You can create a reference system manually as shown below or fetch this information from a close-by tide gauge. This will be shown in the more advanced options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the reference and exclude datums\n",
    "excluded_datums=[\"NAVD88\"]\n",
    "#references=db.WaterlevelReferenceModel(\n",
    "#    reference=\"MSL\",\n",
    "#    datums=[\n",
    "#        db.DatumModel(name=\"MSL\", height=us.UnitfulLength(value=0, units=us.UnitTypesLength.meters)),\n",
    "#        db.DatumModel(name=\"NAVD88\", height=us.UnitfulLength(value=1, units=us.UnitTypesLength.meters))\n",
    "#    ]\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "We can add **sea level rise scenarios** from a csv file wit the columns:  **year, unit, scenario_1, scenario_2, ..., scenario_n**. With that file we create a `SlrScenariosModel` object in which we provide the `file` and the `relative_to_year` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add SLR scenarios\n",
    "slr_scenarios=db.SlrScenariosModel(\n",
    "    file=str(Path(STATIC_DATA_DIR  / \"slr.csv\")),\n",
    "    relative_to_year=2020,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "Let's have a quick look what the slr scenario csv file looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(slr_scenarios.file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "In a similar manner as the slr scenarios, we can add **SCS (Soil Conservation Service) rainfall** to our database by creating a `SCSModel` object, which consist of the `file` and the `type` (Scs type) attributes. The `type` should be passed in form of a `Scstype` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Soil Conservation Service rainfall\n",
    "scs=db.SCSModel(\n",
    "    file=str(Path(STATIC_DATA_DIR / \"scs_rainfall.csv\")),\n",
    "    type=Scstype.type3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "Let's have a quick look what the scs scenario csv file looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(scs.file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "To capture a realistic tide we can add the information from a **tide gauge**. We can either download the data from the NOAA COOPS or pass a csv file ino the `source` attribute of the `TideGaugeConfigModel`. When we download data from NOAA COOPS, we must define a `max_distance` of object type [`UnitfulLength`](../../api_ref/UnitfulLength.qmd) that describes the value (`int`) and unit ([`UnitTypesLength`](../../api_ref/UnitTypesLength.qmd)) of the maximum distance from our model domain to the nearest tide gauges to include.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tide gauges\n",
    "tide_gauge=db.TideGaugeConfigModel(\n",
    "    source=db.TideGaugeSource.noaa_coops,\n",
    "    max_distance=us.UnitfulLength(\n",
    "        value=100, units=us.UnitTypesLength.miles\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "By setting the `cyclones` attribute to `True` we can add **cyclone tracks** to our database. We need to define the ocean basin we are interested in in the `cyclone_basin` attribute. The `Basins` object already has several options for us e.g. `NA` - North Atlantic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cyclone tracks\n",
    "cyclones=True\n",
    "cyclone_basin=db.Basins.NA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "By adding **observation points** we can extract timeseries of water levels from our event scenarios. We can add a list of `ObsPointModel` objects. Each of these objects must have a `name` and a `lat`and `lon`attribute. The `description` and `ID` are optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add observation points\n",
    "obs_point=[\n",
    "    db.ObsPointModel(\n",
    "        name=\"ashley_river\",\n",
    "        description=\"Ashley River - James Island Expy\",\n",
    "        lat=32.7765,\n",
    "        lon=-79.9543,\n",
    "    ),\n",
    "    db.ObsPointModel(\n",
    "        name=8665530,\n",
    "        description=\"Charleston Cooper River Entrance\",\n",
    "        ID=8665530,\n",
    "        lat=32.78,\n",
    "        lon=-79.9233,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "We need to define the **Delft-FIAT model** for our database. All we need for that is to define the folder path that points to the Delft-FIAT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Delft-FIAT model\n",
    "fiat=str(Path(STATIC_DATA_DIR / \"fiat\").absolute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    " <span style=\"color:red;\">Here I have a question - this is only used when there are NO aggregation areas in our model yet? Bc when I run it with an existing aggr layer in the model this crashes.</span>\n",
    "- `aggregation_areas`: A list of dictionaries with the entries: name, file path, field_name. Aggregates the exposure into larger spatial groups o summarize impacts on larger scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add aggregation areas\n",
    "#aggregation_areas=[\n",
    "#db.SpatialJoinModel(\n",
    "#    name=\"aggr_lvl_1\",\n",
    "#    file=str(\n",
    "#        Path(STATIC_DATA_DIR / aggr_lvl_1.geojson\")\n",
    "#    ),\n",
    "#    field_name=\"name\",\n",
    "#),\n",
    "#db.SpatialJoinModel(\n",
    "#    name=\"aggr_lvl_2\",\n",
    "#    file=str(Path(STATIC_DATA_DIR /aggr_lvl_2.geojson\")\n",
    "#    ),\n",
    "#    field_name=\"name\",\n",
    "#),\n",
    "#]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "To refine our Delft-FIAT model we can add additional inputs or update default settings. \n",
    "\n",
    "Sometimes our Delf-FIAT model exposure is in point data By adding the `building_footprints`attribute we can download data from Open Street Map (OSM) using the `FootprintsOptions.OSM` object. e use the building footprints to create the visualizations for the impacts on the building footprint level.  \n",
    "The `fiat_buildings_name` and `fiat_roads_name` are set to *\"buildings\"* and *\"roads\"*, respectively as default. These names capture the geometry names of these assets in the Delft-FIAT model. If you specified different names for these geometry, you must change them here. By defining a value in the `road_width` attribute we can capture the realistic width of the road. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add additional Delft-FIAT parameters\n",
    "building_footprints=db.FootprintsOptions.OSM\n",
    "fiat_buildings_name=\"buildings\"\n",
    "fiat_roads_name=\"roads\"\n",
    "road_width=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "The base flood elevation (BFE) model allows us to elevate homes relative to the BFE. To do so we need to provide a BFE spatial file to the `SpatialJoinModel`, defining the `name` of the spatial file, in this case `bfe` and the `field_name`, which is the column name inside the spatial file that defines the BFE value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add base flood elevation\n",
    "bfe=db.SpatialJoinModel(\n",
    "    file=str(Path(STATIC_DATA_DIR / \"bfe.geojson\")),\n",
    "    name=\"bfe\",\n",
    "    field_name=\"bfe\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "To capture socio-economic impacts we can add a social vulnerability (SVI) layer to the database. We need to define the `file`-path to the spatal SVI file, the `field_name` that captures the column name within the spatial file with the SVI value and the `threshold` at which point an area is classified as vulnerable.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add social vulnerability index\n",
    "svi=db.SviConfigModel(\n",
    "    file=str(Path(STATIC_DATA_DIR / \"CDC_svi_2020.gpkg\")),\n",
    "    field_name=\"SVI\",\n",
    "    threshold=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "Now, that we created all the individual objects we can compile them in the `ConfigModel`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile ConfigModel\n",
    "config_model = db.ConfigModel(name = name,\n",
    "        database_path= database_path,\n",
    "        unit_system= unit_system,\n",
    "        gui=gui,\n",
    "        infographics=infographics,\n",
    "        probabilistic_set=probabilistic_set,\n",
    "        return_periods=return_periods,\n",
    "        sfincs_overland=sfincs_overland,\n",
    "        sfincs_offshore=sfincs_offshore,\n",
    "        dem=dem,\n",
    "        excluded_datums=excluded_datums,\n",
    "        #references=references,\n",
    "        slr_scenarios=slr_scenarios,\n",
    "        scs=scs,\n",
    "        tide_gauge=tide_gauge,\n",
    "        cyclones=cyclones,\n",
    "        cyclone_basin=cyclone_basin,\n",
    "        obs_point=obs_point,\n",
    "        fiat=fiat,\n",
    "        #aggregation_areas=aggregation_areas,\n",
    "        building_footprints=db.FootprintsOptions.OSM,\n",
    "        fiat_buildings_name=fiat_buildings_name,\n",
    "        fiat_roads_name=fiat_roads_name,\n",
    "        bfe=bfe,\n",
    "        svi=svi,\n",
    "        road_width=road_width,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "### üìñ **Step 4b**: Create a configuration file from a **dictionary**\n",
    "From verything that we learned above, we can create a simple dictionary with all the attributes and save it to a configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the configuration file for the database builder for a simple FloodAdapt database. \n",
    "\n",
    "# all paths should be provided with forward slashes (/)\n",
    "config = {\"name\": \"charleston_example_advanced2\",\n",
    " \"database_path\": \"Database\",\n",
    " \"unit_system\": \"imperial\",\n",
    " \"gui\": {\"max_flood_depth\": 5.0,\n",
    "  \"max_aggr_dmg\": 1000000.0,\n",
    "  \"max_footprint_dmg\": 250000.0,\n",
    "  \"max_benefits\": 5000000.0},\n",
    " \"infographics\": True,\n",
    " \"fiat\": \"fiat\",\n",
    " #\"aggregation_areas\": [{\"name\": \"aggr_lvl_1\",\n",
    " #  \"file\": \"aggr_lvl_1.geojson\",\n",
    " #  \"field_name\": \"name\"},\n",
    " # {\"name\": \"aggr_lvl_2\",\n",
    " #  \"file\": \"aggr_lvl_2.geojson\",\n",
    " #  \"field_name\": \"name\"}],\n",
    " \"building_footprints\": \"OSM\",\n",
    " \"fiat_buildings_name\": \"buildings\",\n",
    " \"fiat_roads_name\": \"roads\",\n",
    " \"bfe\": {\"name\": \"bfe\",\n",
    "  \"file\": str(Path(STATIC_DATA_DIR /\"bfe.geojson\")),\n",
    "  \"field_name\": \"bfe\"},\n",
    " \"svi\": {\"name\": None,\n",
    "  \"file\": str(Path(STATIC_DATA_DIR /\"CDC_svi_2020.gpkg\")),\n",
    "  \"field_name\": \"SVI\",\n",
    "  \"threshold\": 0.5},\n",
    " \"road_width\": 5.0,\n",
    " \"return_periods\": [1, 2, 5, 10, 25, 50, 100],\n",
    " \"sfincs_overland\": {\"name\": \"overland\",\n",
    "  \"reference\": \"MSL\",\n",
    "  \"vertical_offset\": None},\n",
    " \"sfincs_offshore\": {\"name\": \"offshore\",\n",
    "  \"reference\": \"MSL\",\n",
    "  \"vertical_offset\": {\"value\": 0.33, \"units\":\"feet\"}},\n",
    " \"dem\": {\"filename\": str(Path(STATIC_DATA_DIR / \"charleston_14m.tif\")),\n",
    "  \"units\": \"meters\"},\n",
    " \"excluded_datums\": [\"NAVD88\"],\n",
    " \"slr_scenarios\": {\"file\": \"slr.csv\",\n",
    "  \"relative_to_year\": 2020},\n",
    " \"scs\": {\"file\": str(Path(STATIC_DATA_DIR / \"scs_rainfall.csv\")),\n",
    "  \"type\": \"type_3\"},\n",
    " \"tide_gauge\": {\"source\":\"noaa_coops\",\n",
    "  \"description\": \"\",\n",
    "  \"max_distance\": {\"value\": 100.0, \"units\": \"miles\"}},\n",
    " \"cyclones\": True,\n",
    " \"cyclone_basin\": \"NA\",\n",
    " \"obs_point\": [{\"name\": \"ashley_river\",\n",
    "   \"description\": \"Ashley River - James Island Expy\",\n",
    "   \"lat\": 32.7765,\n",
    "   \"lon\": -79.9543},\n",
    "  {\"name\": 8665530,\n",
    "   \"description\": \"Charleston Cooper River Entrance\",\n",
    "   \"ID\": 8665530,\n",
    "   \"lat\": 32.78,\n",
    "   \"lon\": -79.9233}],\n",
    " \"probabilistic_set\": \"test_set\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "When we work with a dictionary, we need to save the configuration file as a .toml-file, so that we can call it later when we run the Database Builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the configuration file\n",
    "with open(Path(STATIC_DATA_DIR /\"db_config_advanced.toml\"), \"w\") as f:\n",
    "    toml.dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "## üèÉ‚Äç‚ôÄÔ∏è **Step 5**. Run the Database Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "We are ready to run the Database Builder with the configuration that we just created above. First we are going to run **Option 3a** - in which we generated the configuration using the FloodAdapt classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Option 2a -  DB-builder config from FloodAdapt classes\n",
    "db_build = db.DatabaseBuilder(config_model)\n",
    "db_build.build(overwrite= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "Now we are going to run **Option 3b** - in which we manually created a configuration file from a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Option 2b -  DB-builder config from dictionary\n",
    "config_path = STATIC_DATA_DIR  / \"db_config_advanced.toml\"\n",
    "config = db.ConfigModel.read(config_path)\n",
    "dbs = db.DatabaseBuilder(config)\n",
    "dbs.build(overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "## üöÄ **Step 6.** - Reading-in the FloodAdapt database\n",
    "Now that we built the database we can open it and continue to work with it.  \n",
    "\n",
    "In the other example notebooks in this repository you can find the instructions on how to create and save the single components to create a full scenario (events, measures, strategies, projections) in your database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = Settings(\n",
    "    DATABASE_ROOT=Path(STATIC_DATA_DIR / \"Database\").resolve(),\n",
    "    DATABASE_NAME=\"charleston_example_advanced1\"\n",
    ")\n",
    "fa = FloodAdapt(database_path=settings.database_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "## **Finished!**\n",
    "\n",
    "Congratulations! You created your own FloodAdapt database and know now how to initiate it. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fa_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
